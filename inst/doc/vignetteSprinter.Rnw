% \VignetteIndexEntry{A vignette for R package sprinter}
% \VignettePackage{sprinter}
% \VignetteEngine{knitr::knitr} 
\documentclass{scrartcl}\usepackage[]{graphicx}\usepackage[]{color}
\usepackage{hyperref}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother


\usepackage{framed}

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}

\usepackage{alltt}  
\usepackage[T1]{fontenc}

\bibliographystyle{ieeetr}


\title{sprinter: An R package for screening prognostic interactions}
\author{Isabell Hoffmann, Murat Sariyar, Harald Binder}
\date{\today}






\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\maketitle
\tableofcontents
\section{Introduction}

In order to predict patients' mortality risks, it is of special interest to determine predictive biomarkers.
Multivariate risk prediction models are constructed to predict such mortality risks. 
In order to generate sparse models for molecular data, established methods can be used, that are able to extract important main effects (such as elastic net \cite{Zou2005}, LASSO \cite{tibsh96} and CoxBoost \cite{binder09path}). \\
Some effects arise only if two genes interact, e.g. expression of one gene depends on the expression level of the other gene.
Such interactions may play an important role in molecular applications. \\
Considering all two-way interactions increases the problem of multiple testing enormously. 
Therefore, it is meaningful to pre-select possibly relevant interactions to reduce the number of interactions. 
Machine learning approaches such as penalized regression models \cite{park}, logic regression \cite{schwender}, multifactor-dimensionality reduction \cite{hahn} or random forest \cite{breiman} are able to pre-select relevant interaction terms in high-dimensional datasets.

The package \textit{sprinter} offers a modular framework for pre-selecting important interactions and 
building prognostic models for time-to-event settings \cite{Sariyar2014} by combining available statistical components.
The framework consists of the following three steps (for a detailed explanation, see below):
\begin{itemize}
\item[(1)] Fitting a main effects model
\item[(2)] Modifying the data and pre-selecting interaction terms
\item[(3)] Building a comprehensive considering interactions
\end{itemize}
In addition to the model building step, our package provide a method to evaluate the relevance of selected interactions within the final model.

In the first step of our strategy, a main effects model is fitted in oder to determine the relevant main effects. 
These main effects will be used in the second step to generate a modified data set. 
With this modified data set, 
weaker interaction effects are no longer masked by the stronger main effects. 
After modifying the data, possibly relevant interaction terms are pre-selected.
In the last step, the final model is fitted by using the main effects detected in step (1) and the interaction terms detected in step (2) as covariates.

The package \texttt{sprinter} offers a new approach to interaction detection and has the following achievements:
\begin{enumerate}
  \item The modular structure of this approach leads to the simultaneous consideration of main effects and interactions in high-dimensional data sets.
  \item It is possible to compare the main effects extracted by the main effects model with those selected by the final model in order to assess the relevance of the main effects.
  \item It is a flexible approach in which different statistical methods can be combined in order to perform the different steps. 
\end{enumerate}



\section{Data sets}
\label{sec.data}
To demonstrate how the package works, simulated data sets are provided for which the true effects are known.
The function \texttt{simul.int} creates exponentially distributed survival times with baseline hazard \texttt{lambda}.  
The number of covariates is \texttt{p} 
and the sample size is  \texttt{n}. 
All covariates are standard normally distributed. 
The number of true main effects 
and the number of true interactions are given by \texttt{n.main} and \texttt{n.int}. 
The interactions are generated by multiplications of non-main-effects variables. 
The absolute effect sizes of the main effects is assigned to \texttt{beta.main},
and the absolute effect sizes of the true interactions are assigned to \texttt{beta.int}. 


We use the following settings for simulating the data set:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{library}\hlstd{(sprinter)}
\hlstd{simulation} \hlkwb{<-} \hlkwd{simul.int}\hlstd{(}\hlkwc{seed} \hlstd{=} \hlnum{12345}\hlstd{,}\hlkwc{n} \hlstd{=} \hlnum{200}\hlstd{,} \hlkwc{p} \hlstd{=} \hlnum{500}\hlstd{,}
                          \hlkwc{beta.int} \hlstd{=} \hlnum{1}\hlstd{,}
                          \hlkwc{beta.main} \hlstd{=} \hlnum{0.9}\hlstd{,}
                          \hlkwc{censparam} \hlstd{=} \hlnum{1}\hlopt{/}\hlnum{20}\hlstd{,}
                          \hlkwc{lambda} \hlstd{=} \hlnum{1}\hlopt{/}\hlnum{20}\hlstd{)}
\hlstd{data} \hlkwb{<-} \hlstd{simulation}\hlopt{$}\hlstd{data}
\end{alltt}
\end{kframe}
\end{knitrout}

The function \texttt{simul.int} returns two components: the simulated data set (\texttt{data}) and  information about the main effects and interactions and their effect sizes (\texttt{info}). 
The information about the true main effects and interactions is printed as follows:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{print}\hlstd{(simulation}\hlopt{$}\hlstd{info)}
\end{alltt}
\begin{verbatim}
##        ID Effect size
## 1     ID1         0.9
## 2     ID2        -0.9
## 3 ID3:ID4           1
## 4 ID5:ID6          -1
\end{verbatim}
\end{kframe}
\end{knitrout}


Figure \ref{kmrw} shows the Kaplan-Meier curve of the simulated data set. 
The question we are going to address is the following: Is it possible to find true interactions in such a data set together with true main effects?

\begin{figure}
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/loadsimd} 

}



\end{knitrout}
\caption{Kaplan-Meier simulated data set.}
\label{kmrw}
\centering
\end{figure}




\section{How to use sprinter}
\subsection{Using existing functions}
\label{sec.usage}
\texttt{sprinter} provides a prognostic model after pre-selecting relevant interactions and main effects.
Methods for pre-selecting the important variables can be set in the arguments \texttt{screen.main} and \texttt{screen.inter}. 
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{sprinter}\hlstd{(x,}
         \hlstd{time,}
         \hlstd{status,}
         \hlkwc{mandatory}\hlstd{=} \hlkwa{NULL}\hlstd{,}
         \hlkwc{repetitions} \hlstd{=} \hlnum{25}\hlstd{,}
         \hlkwc{n.inter.candidates} \hlstd{=}\hlnum{1000}\hlstd{,}
         \hlstd{screen.main,}
         \hlkwc{screen.inter} \hlstd{= fit.rf,}
         \hlkwc{fit.final} \hlstd{= screen.main,}
         \hlkwc{args.screen.main} \hlstd{=} \hlkwd{list}\hlstd{(),}
         \hlkwc{args.screen.inter} \hlstd{=} \hlkwd{list}\hlstd{(),}
         \hlkwc{args.fit.final} \hlstd{= args.screen.main,}
         \hlkwc{orthogonalize} \hlstd{=} \hlnum{TRUE}\hlstd{,}
         \hlkwc{parallel} \hlstd{=} \hlnum{FALSE}\hlstd{,} \hlkwc{mc.cores} \hlstd{=} \hlkwd{detectCores}\hlstd{(), ...)}
\end{alltt}
\end{kframe}
\end{knitrout}
To pre-select the important main effects, it is possible to perform CoxBoost or univariate Cox regressions; the parameter \texttt{screen.main} accepts a value in the form of a function to indicate the desired approach. 
Using the function \texttt{fit.CoxBoost} means to select the main effects which are chosen by CoxBoost and using \texttt{fit.uniCox} means to select variables with adjusted p-values \cite{Wright1992} smaller than \texttt{sig}. 
Functions \texttt{fit.CoxBoost} and \texttt{fit.uniCox} are adapted function for the usage in \texttt{sprinter} (see more information in Section \ref{sec.impl}).
The arguments for the methods used for screening the main effects can be set in \texttt{args.screen.main}.

Correspondently, the approach for screening interactions is assigned to \texttt{screen.inter}. 
It is possible to perform this step by using random forest (\texttt{screen.inter = fit.rf}) or by using logic regression (\texttt{screen.inter = fit.logicReg}).
For more information about the structure of the adapted functions \texttt{fit.rf} and \texttt{fit.logicReg}, see Section \ref{sec.impl}.
By using random forest for each variable, a variable importance measurement is calculated that considers the underlying interaction structure and reflects the meaning of a variable for the forest. 
By default the permutation accuracy importance \cite{Ishwaran2010} is used for evaluating the variables in the forest. 
This measure can be replaced by other importance measures such as minimal depth. The variable importance is used to construct the relevant interactions for the model. The  random forest arguments can be set in \texttt{args.screen.inter}.

In very large data sets the number of variables must be restricted in order to preselect relevant interactions. 
To be able to perform random forest or logic regression in such data sets, use \texttt{fit.rf.select}, respectively \texttt{fit.logicReg.select}. These functions restrict the data set by selecting the variables with the \texttt{n.select} smallest p-values evaluated by univariate Cox regressions before performing random forest, respectively the logic regression.


%Orthogonalization
Before pre-selecting the interactions, the data are modified such that weaker interactions can be detected more easily (orthogonalize = TRUE). 
All variables are orthogonalized to those that are assessed as main effects in the first step.

%Subsamples:\\
For better stabilization subsamples are created and random forests are performed on each subsampled data set.
The number of subsamples can be set in \texttt{repetitions} (default value: 25). 
To summarize the results of all subsamples, variable inclusion frequencies (VIFs) of the constructed interactions terms are computed and the \texttt{n.inter.candidates} most frequent pairs are selected as relevant interaction terms.
As the pre-selection of interactions can be computationally expensive it is possible to parallelize this step by \texttt{parallel = TRUE}.

Further approaches for screening main effects and interactions can be implemented by the user, see Section \ref{sec.impl}.

As an example we perform \texttt{sprinter} to screen main effects by CoxBoost and to detect interactions by random forest:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hlstd{(}\hlnum{518}\hlstd{)}
\hlstd{testcb} \hlkwb{<-} \hlkwd{sprinter}\hlstd{(} \hlkwc{x}\hlstd{=data[,}\hlnum{1}\hlopt{:}\hlnum{500}\hlstd{],}
                    \hlkwc{time} \hlstd{= data}\hlopt{$}\hlstd{obs.time,}
                    \hlkwc{status}\hlstd{= data}\hlopt{$}\hlstd{obs.status,}
                    \hlkwc{repetitions} \hlstd{=} \hlnum{25}\hlstd{,}
                    \hlkwc{mandatory} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"ID1"}\hlstd{,}\hlstr{"ID2"}\hlstd{),}
                    \hlkwc{n.inter.candidates} \hlstd{=} \hlnum{10000}\hlstd{,}
                    \hlkwc{screen.main} \hlstd{= fit.CoxBoost,}
                    \hlkwc{screen.inter} \hlstd{= fit.rf,}
                    \hlkwc{fit.final} \hlstd{= fit.CoxBoost,}
                    \hlcom{#args.screen.main = list(seed=123, stepno = 10, }
                    \hlcom{#                        K = 10, criterion ='pscore',}
                    \hlcom{#                        nu = 0.05),}
                    \hlkwc{parallel} \hlstd{=} \hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

Clinical covariates can be specified in the argument \texttt{mandatory} as a vector to be forcefully included in a model. In this example we set the main effects "ID1" and "ID2" to mandatory; these are the colnames of the mandatory covariates in the data set \texttt{data}.
To build the final model, the user can choose between CoxBoost and univariate Cox-regression, as in the main effects model building step. 
In contrast to building the main effects model, the final model is constructed using the variables selected in the main effects model plus the \texttt{n.inter.candidates} pre-selected interactions of the screening step. In this example we choose CoxBoost for fitting the final model. As an example for using \texttt{args.screen.main}, a comment is included on how to set arguments for the CoxBoost approach. 
For more information about using CoxBoost see \cite{buhl07} .

As a result, \texttt{sprinter} prints the candidates for interactions with the largest inclusion frequencies together with the final model.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{print}\hlstd{(testcb)}
\end{alltt}
\begin{verbatim}
## Top 20 Interaction Candidates with Inclusion Frequencies: 
##      ID2:ID1    ID19:ID1   ID329:ID1     ID4:ID1    ID19:ID2   ID329:ID2 
##          24          23          23          22          22          22 
##   ID329:ID4    ID54:ID1    ID73:ID1     ID4:ID2  ID329:ID19   ID144:ID1 
##          22          21          21          21          21          20 
##   ID303:ID1    ID54:ID2    ID73:ID2    ID19:ID4   ID303:ID4   ID54:ID19 
##          20          20          20          20          20          20 
##   ID73:ID19 ID329:ID303 
##          20          20 
## 
##  Final model: 
##  
## 35 boosting steps resulting in 11 non-zero coefficients (with 2 
## being mandatory) 
## partial log-likelihood: -403.6513
\end{verbatim}
\end{kframe}
\end{knitrout}

In this example the final model consists of eleven variables.
To obtain more information about the variables selected in the models call \texttt{summary()}, as in the following command:


\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(testcb)}
\end{alltt}
\begin{verbatim}
## Main candidates with coefficients: 
##         ID1         ID2         ID4        ID12        ID37 
##  0.99687801 -0.70730288  0.01396648  0.02875253 -0.15896531 
## 
##  Top 20 Interaction Candidates with Inclusion Frequencies: 
##     ID2:ID1    ID19:ID1   ID329:ID1     ID4:ID1    ID19:ID2   ID329:ID2 
##          24          23          23          22          22          22 
##   ID329:ID4    ID54:ID1    ID73:ID1     ID4:ID2  ID329:ID19   ID144:ID1 
##          22          21          21          21          21          20 
##   ID303:ID1    ID54:ID2    ID73:ID2    ID19:ID4   ID303:ID4   ID54:ID19 
##          20          20          20          20          20          20 
##   ID73:ID19 ID329:ID303 
##          20          20 
## 
##  Final Model: 
## 35 boosting steps resulting in 11 non-zero coefficients (with 2 being 
## mandatory) 
## partial log-likelihood: -403.6513 
## 
## Parameter estimates for mandatory covariates at boosting step 35:
##     Estimate
## ID1   0.9792
## ID2  -0.7772
## 
## Optional covariates with non-zero coefficients at boosting step 35:
## parameter estimate > 0:
##  ID1, ID3:ID4, ID4:ID373, ID18:ID321, ID267:ID319 
## parameter estimate < 0:
##  ID2, ID37, ID39:ID358, ID214:ID412, ID230:ID319, ID401:ID498
\end{verbatim}
\end{kframe}
\end{knitrout}

The summary of \texttt{sprinter} shows the main candidates with their coefficients, the interaction candidates with the largest inclusion frequencies and gives information about the final model.
In this example the true interaction ID3:ID4 is selected in the final model with the correct sign for its parameter estimate.
The second interaction ID5:ID6 is not included in this model; instead, seven interactions and one main effect are selected which have no effect on the outcome. 

For real data sets the true main effects and interactions are unknown. In order to distinguish between true and false positive interactions, a subsampling step using \texttt{resample.sprinter}, which is a wrapper, is performed. See Section \ref{sec.evalint}.

If the user wants to perform predictions with the final model, this package provides the S3 method \texttt{predict}, which can be applied to objects of class \texttt{sprinter}.


\subsection{Evaluating interactions}
\label{sec.evalint}
The \texttt{sprinter} package provides the possibility to evaluate the relevance of an interaction by using resampling techniques \cite{Sauerbrei2011} and the resultant variable inclusion frequency (VIF). 
The implemented wrapper \texttt{resample.sprinter} subsamples the original data set \texttt{fold}-times and applies the whole procedure to each subsample. 
The proportion of samples that should be drawn from the original data set can be set in the argument \texttt{oob.rel} (default value: 0.632).
The results of this wrapper are inclusion frequencies and mean coefficients of each interaction term.


As an example we perform the function \texttt{resample.sprinter} on the data set we simulated in Section \ref{sec.data}. 
For the purpose of displaying the results, we set the number of subsamples to 25 with a subsampling frequency of 0.632.
Although 20 cores are used for running this operation, it needs about 15 minutes (\texttt{system.time}) to run. 
If the user intends to test the function, it is possible reduce the system time by reducing the values for \texttt{fold} and \texttt{repetitions}.
On each subsample, the function \texttt{sprinter} is applied as in the previous example (see Section \ref{sec.usage}). 

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{set.seed}\hlstd{(}\hlnum{123}\hlstd{)}
\hlstd{resamcb} \hlkwb{<-} \hlkwd{resample.sprinter}\hlstd{(}  \hlkwc{x}\hlstd{=data[,}\hlnum{1}\hlopt{:}\hlnum{500}\hlstd{],}
                               \hlkwc{time} \hlstd{= data}\hlopt{$}\hlstd{obs.time,}
                               \hlkwc{status}\hlstd{= data}\hlopt{$}\hlstd{obs.status,}
                               \hlkwc{fold} \hlstd{=} \hlnum{25}\hlstd{,}
                               \hlkwc{oob.rel} \hlstd{=} \hlnum{0.632}\hlstd{,}
                               \hlkwc{repetitions} \hlstd{=} \hlnum{25}\hlstd{,}
                               \hlkwc{mandatory} \hlstd{=} \hlkwd{c}\hlstd{(}\hlstr{"ID1"}\hlstd{,}\hlstr{"ID2"}\hlstd{),}
                               \hlkwc{n.inter.candidates} \hlstd{=} \hlnum{1000}\hlstd{,}
                               \hlkwc{screen.main} \hlstd{= fit.CoxBoost,}
                               \hlkwc{screen.inter} \hlstd{= fit.rf,}
                               \hlkwc{fit.final} \hlstd{= fit.CoxBoost,}
                               \hlkwc{parallel} \hlstd{= T,}\hlkwc{mc.cores} \hlstd{=} \hlnum{20}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}


For showing the results the summary() provides a plot of the mean coefficients of each selected variable with their single coefficients and displays the mean coefficients of the interactions with variable inclusion frequencies larger than $1/\texttt{fold}$.

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(resamcb)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/printsumresamcb} 

}


\begin{kframe}\begin{verbatim}
##             Variable Inclusion Frequency Mean Coefficient
## ID3:ID4                             0.44       0.41023042
## ID5:ID6                             0.16      -0.31689659
## ID1:ID330                           0.12      -0.08676463
## ID208:ID390                         0.12       0.09053558
## ID4:ID358                           0.12      -0.02938755
## ID1:ID300                           0.12      -0.05811525
## ID214:ID412                         0.12      -0.10781557
## ID1:ID78                            0.08       0.05196649
## ID71:ID361                          0.08      -0.08750961
## ID101:ID440                         0.08       0.05351890
## ID290:ID370                         0.08      -0.03989412
## ID2:ID10                            0.08       0.09813999
## ID394:ID447                         0.08      -0.04496056
\end{verbatim}
\end{kframe}
\end{knitrout}
The plot generated by \texttt{summary()} shows that the clinical covariates ID1 and ID2 are the strongest main effects (on average 1.0234 and -0.7845). 
There are many false positive main effects and interactions in the final model which are chosen only once. 
To distinguish between the true and the false positive interactions, the user can consult the variable inclusion frequencies in the provided table.
This table shows the variable inclusion frequencies and the mean coefficients of the variables selected more often than once.
The true interactions have the highest variable inclusion frequencies of 44 percent and 16 percent.
All other interactions have inclusion frequencies of 12 percent and lower.

For plotting the coefficients of the optional variables without the mandatory ones, the user can set the argument \texttt{optional = TRUE}.
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{plot}\hlstd{(resamcb,} \hlkwc{optional.only} \hlstd{= T)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/plot_resamcb_optio} 

}



\end{knitrout}


\subsection{Implementing new functions for pre-selecting covariates.}
\label{sec.impl}
In the current version of the package some methods are available to pre-select main effects or to build the final model.
It is easy to add further methods by implementing new functions.
By writing a new function for pre-selecting main effects ,the user should at least enclose the following arguments for committing the data: % with a special form. 
\texttt{time}, \texttt{status}, \texttt{x} and \texttt{unpen.index}.

As an example the code of the function \texttt{fit.uniCox} is printed as follows:
\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fit.uniCox}
\end{alltt}
\begin{verbatim}
## function (time, status, x, unpen.index = NULL, method = "bonferroni", 
##     sig = 0.05, ...) 
## {
##     pvalue <- beta <- rep(NA, ncol(x))
##     for (i in 1:ncol(x)) {
##         res <- coxph(Surv(time, status) ~ x[, i])
##         pvalue[i] <- summary(res)$coefficients[, 5]
##         beta[i] <- summary(res)$coefficients[, 1]
##     }
##     pvalueadjust <- p.adjust(p = pvalue, method = method)
##     indmain <- unique(c(which(pvalueadjust < sig), unpen.index))
##     datamulti <- as.data.frame(x[, indmain])
##     cox <- coxph(Surv(time, status) ~ ., data = datamulti)
##     res <- list()
##     res$model <- cox
##     res$xnames <- colnames(x)[indmain]
##     res$indmain <- indmain
##     res$beta <- coefficients(cox)
##     return(res)
## }
## <environment: namespace:sprinter>
\end{verbatim}
\end{kframe}
\end{knitrout}

In the first part of the function the main effects are identified using univariate Cox regressions.
All variables with univariate adjusted $p$-values smaller than the significance level \texttt{sig} are used for fitting the multivariate model.
In the second part of the function the multivariate Cox regression is fitted. 

The resultant object returns a list comprising the following components:
\begin{description}
  \item[\texttt{model}] Cox proportional hazards model
  \item[\texttt{xnames}] Names of the selected covariates 
  \item[\texttt{indmain}] Vector containing their indices 
  \item[\texttt{beta}] Vector of coefficients
\end{description}

If the user wants to implement a new function for pre-selecting interactions, the function has to enclose the following arguments:\\
  \begin{tabular}{ll}
    nr: & Value for displaying the actual resampling run.\\
    data: & Data frame containing the y-outcome and x-variables in the model.\\
    indices: & Indices indicating the samples of the subsample.\\
    seed.interselect: & Seed for random number generator.
  \end{tabular}

As an example the code of the function \texttt{fit.rf} is printed as follows:

\begin{knitrout}
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fit.rf}
\end{alltt}
\begin{verbatim}
## function (nr, data, indices, seed.interselect, ...) 
## {
##     cat(nr)
##     rsf <- rfsrc(Surv(time, status) ~ ., data = data[indices, 
##         ], big.data = T, seed = seed.interselect)
##     return(rsf$importance)
## }
## <environment: namespace:sprinter>
\end{verbatim}
\end{kframe}
\end{knitrout}

As a result, the function must provide a vector containing a variable importance measure for each variable in the data.
This measure must be interpretable in such a way that a positive value indicates that the investigated variable is relevant.

\bibliography{bibVignette}


\end{document}
